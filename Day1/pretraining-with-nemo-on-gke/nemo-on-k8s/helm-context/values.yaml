targetPlatform: "gke"
#queue: "multislice-queue"

volumes:
  # The VM host path for SSDs is assumed at /mnt/stateful_partition/kube-ephemeral-ssd
  ssdMountPath: "/ssd"

# This mounts any persistent volume claims present in the cluster:
#  pvcMounts:
#  - name: <shared-file-system>
#    mountPath: "/nfs"

# This requires GCS fuse driver installed:
  # gcsMounts:
  #   - bucketName: "mhvictorhau" #"gs://mhvictorhau/mixtral8x7b"
  #     mountPath: "/gcs"

gcsDownload: # downloads or synchronizes contents of a GCS bucket folder on initialization
  source: "gs://injae-download/megatron-lm/wikipedia/" 
  #source: "gs://nemo-megatron-demo/training-data/tokenized/sentencepiece-llama2/wikipedia" 
  target: "/ssd/.cache/"

workload:
  image: "us-central1-docker.pkg.dev/injae-sandbox-340804/a3-bootcamp-labs/nemofw-tcpxo:dev" #"us-central1-docker.pkg.dev/supercomputer-testing/sufkha-nemo-demo-test/nemo-benchmarks-v3:24.03.01.framework"
  torchDistributedTarget: "/opt/NeMo/nemo/collections/nlp/models/language_modeling/megatron_gpt_model.py"

  # It will be mounted to /nfs on container startup using GCS fuse
  gcsBucketForDataCataPath: elm-benchmark

  gpus: 16 # This should be one of: {<= 8,  multiple of 8}
  arguments:
  # These argument name will be prefixed with '+' (see https://hydra.cc/docs/advanced/override_grammar/basic/)
  - name: "exp_manager.explicit_log_dir"
    value: "/nemo-experiments/results" 
  - name: "exp_manager.exp_dir"
    value: "/nemo-experiments/"
  - name: "model.data.data_prefix"
    value: "[1.0,/ssd/.cache/wikipedia-tokenized-for-gpt2]"
  - name: "model.data.index_mapping_dir"
    value: "/gcs/index_mapping_dir"
#  - name: "model.data.data_prefix"
#    value: "[1.0,/ssd/.cache/wikipedia-tokenized-for-llama2]"    
#  - name: "model.tokenizer.model"
#    value: "/ssd/.cache/llama-2-7b-megatron-checkpoint/tokenizer.model"     

  # If not 'null', launches a Tensorboard server on first node. By design, the job will then not exit on first node.
  # This is primarly intended for debugging purposes, when a shared file-system or external Tensorboard is unavailable.  
  embeddedTensorboardTarget: null

network:
  stack: "tcpxo" # one of {"tcp", "tcpx", "tcpxo"}

  daemonVersion: "us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/tcpgpudmarxd-dev:v1.0.8"
  pluginVersion: "us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpxo/nccl-plugin-gpudirecttcpx-dev:v1.0.1"
    

  ncclSettings:
  - name: TRAINING_FILENAME
    value: "mixtral-8x7b-nvidia-configs.yaml" #"llama2-7b.yaml"
  - name: IMAGE_VERSION
    value: "24.05" #"24.03.01.framework"
    
  - name: NCCL_DEBUG
    value: "VERSION"
  - name: NCCL_ALGO
    value: "Ring,Tree"

  # The following NCCL settings are recommended for TCPxo only (but tunable):
  - name: NCCL_MIN_NCHANNELS
    value: "4"

